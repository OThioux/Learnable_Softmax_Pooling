{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:53:43.334808: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-10 08:53:43.474283: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-10 08:53:47.860154: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-07-10 08:53:47.860530: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-07-10 08:53:47.860570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Eager Execution Enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:53:58.883405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:53:59.180777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:53:59.181040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import keras.metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import albumentations\n",
    "from utils import *\n",
    "import skimage\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_input_shape = (224, 224)\n",
    "model_feature_map_shape = tuple(np.asarray(model_input_shape) // 32)\n",
    "no_classes = 20\n",
    "alpha_loss = 0.75  # Class, SAL\n",
    "beta_loss = 1.0 - alpha_loss # SAL\n",
    "model_name = \"model_softmax_part_class_alpha_0.75_mult\"\n",
    "full_dataset = False\n",
    "schedule = False\n",
    "schedule_change = 0.01\n",
    "pool_layer = \"softmax\"  # \"softmax\" \"class_softmax\" \"GeM\" \"mean\" \"max\"\n",
    "load_model = False\n",
    "train = True\n",
    "combined_loss_li = []\n",
    "cce_loss_li = []\n",
    "sal_loss_li = []\n",
    "train_size = 0.9\n",
    "use_max = False\n",
    "learning_rate = (0.00005 * 0.5) if full_dataset else 0.00005 * 0.5\n",
    "beta_lr_factor = 3.0 if full_dataset else 320 # Default 10\n",
    "beta_start_val = 0.0\n",
    "max_beta_val = 2.5  # default 2.5\n",
    "epochs = 20 if full_dataset else 75\n",
    "loss = \"BCE\" # \"BCE\" \"CCE\"\n",
    "# base_model = tf.keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\")\n",
    "# base_model = tf.keras.applications.ResNet50V2(include_top=False, weights=\"imagenet\")\n",
    "predictions_hist_train = []\n",
    "predictions_hist_test = []\n",
    "no_images = len(os.listdir(\"../../pascal/output/boxes\")) if full_dataset else len(os.listdir(\"../../dataset/seg\"))\n",
    "\n",
    "no_models = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "transform = albumentations.Compose([\n",
    "    # albumentations.RandomCrop(width=224, height=224),\n",
    "    albumentations.RandomCrop(width=model_input_shape[0], height=model_input_shape[1]),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    # albumentations.RandomBrightnessContrast(p=0.2, brightness_limit=0.1, contrast_limit=0.1),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(\"../../dataset/train_set.csv\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "classes_mat = classes_df.drop(columns=[\"Id\"]).to_numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def load_image_and_mask(im_no):\n",
    "    im_no = int(im_no)\n",
    "    img = np.load(f\"../../dataset/img/train_{im_no}.npy\")\n",
    "    seg = np.load(f\"../../dataset/seg/train_{im_no}.npy\")\n",
    "    classes = classes_mat[im_no]\n",
    "    return tf.convert_to_tensor(img, dtype=tf.uint8), tf.convert_to_tensor(seg, dtype=tf.uint8), tf.convert_to_tensor(classes, dtype=tf.uint8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def tf_load_image_and_mask(im_no_t):\n",
    "    image, mask, classes = tf.py_function(\n",
    "        func=load_image_and_mask,    # Python function to call\n",
    "        inp=[im_no_t],                 # Input tensor\n",
    "        Tout=[tf.uint8, tf.uint8, tf.uint8]  # Output data types\n",
    "    )\n",
    "\n",
    "    # Set static shapes (important for TensorFlow pipelines)\n",
    "    image.set_shape([model_input_shape[0], model_input_shape[1], 3])\n",
    "    mask.set_shape([model_input_shape[0], model_input_shape[1], 1])\n",
    "    return image, mask, classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "augment_image_and_mask = make_augement_image_and_mask(transform, model_input_shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def tf_augment_image_and_mask(image, mask, classes):\n",
    "    image, mask = tf.py_function(\n",
    "        func=augment_image_and_mask,    # Python function to call\n",
    "        inp=[image, mask],                 # Input tensor\n",
    "        Tout=[tf.float32, tf.uint8]  # Output data types\n",
    "    )\n",
    "    # Set static shapes (important for TensorFlow pipelines)\n",
    "    image.set_shape([model_input_shape[0], model_input_shape[1], 3])\n",
    "    mask.set_shape([model_input_shape[0], model_input_shape[1], no_classes + 1])\n",
    "    return image, mask, classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 08:53:59.992943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-10 08:53:59.995565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:53:59.996775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:53:59.997769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:54:00.740201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:54:00.740477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:54:00.740634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-07-10 08:54:00.740764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2468 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.arange(749))  # the number of dataset items I've got\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda img_id: tf_load_image_and_mask(img_id), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "dataset = dataset.map(lambda image, mask, classes: tf_augment_image_and_mask(image, mask, classes), num_parallel_calls=tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def spatial_consistency_loss(score_map, heatmap, transformation):\n",
    "    \"\"\"\n",
    "    Computes the Spatial Consistency Loss (SCL).\n",
    "    Args:\n",
    "        score_map (tf.Tensor): Current spatial score map (F^t_n), shape [batch_size, G, G, num_classes].\n",
    "        heatmap (tf.Tensor): Running average heatmap (H^{t-1}_n), shape [batch_size, W, W, num_classes].\n",
    "        transformation (tf.Tensor): Augmentation transformation applied to the input (e.g., crop, flip).\n",
    "    Returns:\n",
    "        tf.Tensor: The SCL value.\n",
    "    \"\"\"\n",
    "    # Apply the transformation (e.g., cropping, flipping) to the heatmap\n",
    "    transformed_heatmap = tf.image.resize(heatmap, score_map.shape[1:3], method='bilinear')\n",
    "    # Compute the L1 distance\n",
    "    scl = tf.reduce_mean(tf.abs(score_map - transformed_heatmap))\n",
    "    return scl\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def resize_to_input_tf(seg_masks):\n",
    "    # Resize masks\n",
    "    resized_masks = tf.image.resize(\n",
    "        seg_masks,\n",
    "        size=model_input_shape[:2],\n",
    "        method=tf.image.ResizeMethod.BILINEAR\n",
    "    )\n",
    "    return resized_masks\n",
    "\n",
    "\n",
    "resize_to_output_tf = make_resize_to_output_tf(model_input_shape, model_feature_map_shape)\n",
    "\n",
    "def custom_loss_function(alpha=1.0, beta=1.0):\n",
    "    \"\"\"\n",
    "    Combines Spatial Consistency Loss and Categorical Cross-Entropy Loss.\n",
    "    Args:\n",
    "        alpha (float): Weight for the CCE loss.\n",
    "        beta (float): Weight for the SCL loss.\n",
    "    Returns:\n",
    "        function: A callable loss function to use during model training.\n",
    "    \"\"\"\n",
    "    # mae = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "    def loss_function(y_true, y_pred, seg_masks, heatmap, test=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            y_true (tf.Tensor): Ground-truth class labels, shape [batch_size, num_classes].\n",
    "            y_pred (tf.Tensor): Predicted class probabilities, shape [batch_size, num_classes].\n",
    "            num_classes: Number of classes\n",
    "            seg_masks: segmentation masks Shape: (batch, x, y, k)\n",
    "            heatmap: Attention heatmaps\n",
    "        Returns:\n",
    "            tf.Tensor: The combined loss value.\n",
    "        \"\"\"\n",
    "        # Compute categorical cross-entropy loss\n",
    "        # print(\"Categorical\", y_true.shape, y_pred.shape)\n",
    "        if loss == \"CCE\":\n",
    "            cce_loss = tf.keras.losses.CategoricalCrossentropy()(y_true, y_pred[:,:])\n",
    "        elif loss == \"BCE\":\n",
    "            cce_loss = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred[:,:])\n",
    "        # heatmap_resized = resize_to_input_tf(heatmap)\n",
    "        # print(seg_masks[:,:,:,1:].shape)\n",
    "        seg_masks_resized = resize_to_output_tf(seg_masks, heatmap.shape[1:])\n",
    "        # print(heatmap.dtype, seg_masks_resized.dtype)\n",
    "        # print(heatmap.shape, seg_masks_resized.shape)\n",
    "        # print(seg_masks.numpy())\n",
    "        # tf.print(heatmap_resized)\n",
    "        # plt.imshow(to_ordinal(heatmap_resized.numpy()))\n",
    "        # plt.show()\n",
    "        # mae_loss = tf.keras.losses.MeanSquaredError()(seg_masks, heatmap_resized)\n",
    "        # mae_loss = tf.keras.losses.CategoricalCrossentropy()(seg_masks, heatm\n",
    "        if loss == \"CCE\":\n",
    "            mae_loss = tf.keras.losses.CategoricalCrossentropy()(seg_masks_resized[:,:,:,:], heatmap[:,:,:,:])\n",
    "        elif loss == \"BCE\":\n",
    "            mae_loss = tf.keras.losses.BinaryCrossentropy()(seg_masks_resized[:,:,:,:], heatmap[:,:,:,:])\n",
    "        # print(tf.keras.losses.CategoricalCrossentropy()(seg_masks_resized.numpy(), np.full(seg_masks_resized.shape, 1, dtype=np.float32)))\n",
    "        # print(tf.keras.losses.CategoricalCrossentropy()(seg_masks_resized.numpy(), np.zeros(seg_masks_resized.shape) + 0.0001))\n",
    "        # print(seg_masks_resized[5,:,:,15])\n",
    "\n",
    "        # print(mae_loss, tf.keras.metrics.MeanSquaredError()(seg_masks, heatmap_resized))\n",
    "        # m_iou.update_state(seg_masks, heatmap_resized)\n",
    "\n",
    "        # # Compute spatial consistency loss\n",
    "        # scl_loss = spatial_consistency_loss(score_map, heatmap, transformation)\n",
    "        # if test:\n",
    "        #     print(cce_loss, y_true.shape, y_pred.shape)\n",
    "        #     # tf.print(y_pred[:,1:])\n",
    "        #     tf.print(\"pred class:\", tf.reduce_min(y_pred[:,1:]), tf.reduce_max(y_pred[:,1:]), tf.norm(y_pred[:,1:]))\n",
    "        #     tf.print(\"pred seg:\", tf.reduce_min(heatmap_resized), tf.reduce_max(heatmap_resized), tf.norm(heatmap_resized))\n",
    "        # Combine the two losses\n",
    "        total_loss = alpha * cce_loss + beta * mae_loss\n",
    "        if test:\n",
    "            return total_loss, cce_loss, mae_loss\n",
    "        return total_loss\n",
    "\n",
    "    return loss_function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def train_step(model, optimizer, images, seg_maps, labels, loss_fn, beta_optimizer):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Forward pass: predict class probabilities and score maps\n",
    "        score_map, class_preds = model(images, training=True)\n",
    "\n",
    "        # Compute the combined loss\n",
    "        loss = loss_fn(labels, class_preds[:,1:], seg_maps, score_map, test=False)\n",
    "\n",
    "    # Separate trainable variables\n",
    "    beta_variables = []\n",
    "    other_variables = []\n",
    "    for var in model.trainable_variables:\n",
    "        if \"softmax_pooling\" in var.name and \"beta\" in var.name:\n",
    "            beta_variables.append(var)\n",
    "        other_variables.append(var)\n",
    "\n",
    "    # Backward pass: compute gradients for beta variables\n",
    "    beta_gradients = tape.gradient(loss, beta_variables)\n",
    "\n",
    "    # Backward pass: compute gradients for other variables\n",
    "    other_gradients = tape.gradient(loss, other_variables)\n",
    "\n",
    "    del tape\n",
    "\n",
    "    # Apply gradients to beta variables with a higher learning rate\n",
    "    if beta_gradients:\n",
    "        beta_optimizer = tf.keras.optimizers.Adam(learning_rate=optimizer.learning_rate * beta_lr_factor)\n",
    "        beta_optimizer.apply_gradients(zip(beta_gradients, beta_variables))\n",
    "        del beta_optimizer\n",
    "\n",
    "    # Apply gradients to other variables with the original learning rate\n",
    "    optimizer.apply_gradients(zip(other_gradients, other_variables))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def val_step(model, images, seg_maps, labels, loss_fn):\n",
    "    score_map, class_preds = model(images, training=False)\n",
    "    predictions_hist_test[-1] += list(np.dstack((class_preds.numpy()[:,1:], np.asarray(labels))))\n",
    "    loss = loss_fn(labels, class_preds[:,1:], seg_maps[:,:,:,1:], score_map[:,:,:,1:], test=True)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_model(model, dataset, epochs, optimizer, alpha, beta, losses=None, train_split=0.8, beta_optimizer=None):\n",
    "    \"\"\"\n",
    "    Train the model using the custom train_step function.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): The neural network model.\n",
    "        dataset (tf.data.Dataset): Dataset containing input images and labels.\n",
    "        epochs (int): Number of training epochs.\n",
    "        optimizer (tf.keras.optimizers.Optimizer): Optimizer for training.\n",
    "        alpha (float): Weight for categorical cross-entropy loss.\n",
    "        beta (float): Weight for spatial consistency loss.\n",
    "    \"\"\"\n",
    "    if losses is None:\n",
    "        losses = []\n",
    "    best_loss = np.inf\n",
    "\n",
    "    train_data = dataset.take(int(train_split * no_images)).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "    test_data = dataset.skip(int(train_split * no_images)).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "    # Initialize heatmaps as a dictionary for each image in the datase\n",
    "\n",
    "    # model.compile(optimizer='adam')\n",
    "    if pool_layer == \"softmax\":\n",
    "        print(f\"Softmax weight = {model.trainable_variables[-1]}\")\n",
    "    for epoch in range(epochs):\n",
    "        if schedule:\n",
    "            alpha -= schedule_change\n",
    "            beta += schedule_change\n",
    "        alpha = np.clip(alpha, 0.0, 1.0)\n",
    "        beta = np.clip(beta, 0.0, 1.0)\n",
    "        loss_fn = custom_loss_function(alpha, beta)\n",
    "        predictions_hist_test.append([])\n",
    "        print(f\"\\nEpoch {epoch + 1}/{epochs} \\nAlpha = {alpha}, Beta = {beta}\")\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for step, (images, seg_maps, labels) in enumerate(tqdm(train_data)):\n",
    "            # print(tf.shape(images))\n",
    "            # batch_size = tf.shape(images)[0]\n",
    "\n",
    "            # Perform a training step\n",
    "            loss = train_step(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                images=images,\n",
    "                labels=labels,\n",
    "                seg_maps=seg_maps,\n",
    "                loss_fn=loss_fn,\n",
    "                beta_optimizer=beta_optimizer\n",
    "            )\n",
    "            epoch_loss += loss.numpy()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / (step + 1)\n",
    "        print(f\"Epoch {epoch + 1}: Loss = {avg_epoch_loss}\")\n",
    "        losses.append(avg_epoch_loss)\n",
    "        if \"softmax\" in pool_layer:\n",
    "            print(f\"Softmax weight = {model.trainable_variables[-1]}\")\n",
    "\n",
    "\n",
    "        epoch_test_loss, epoch_cce, epoch_sal = 0, 0, 0\n",
    "        for step, (images, seg_maps, labels) in enumerate(test_data):\n",
    "\n",
    "            combined_loss, cce_loss, sal_loss = val_step(model, images, seg_maps, labels, loss_fn)\n",
    "            epoch_test_loss += combined_loss.numpy()\n",
    "            epoch_cce += cce_loss.numpy()\n",
    "            epoch_sal += sal_loss.numpy()\n",
    "\n",
    "        avg_epoch_test_loss = epoch_test_loss / (step + 1)\n",
    "        avg_epoch_cce = epoch_cce / (step + 1)\n",
    "        avg_epoch_sal = epoch_sal / (step + 1)\n",
    "\n",
    "        combined_loss_li.append(avg_epoch_test_loss)\n",
    "        cce_loss_li.append(avg_epoch_cce)\n",
    "        sal_loss_li.append(avg_epoch_sal)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}: Val loss = {avg_epoch_test_loss}, CCE loss = {avg_epoch_cce}, SAL loss = {avg_epoch_sal}\")\n",
    "\n",
    "        if avg_epoch_test_loss < best_loss:\n",
    "            best_loss = avg_epoch_test_loss\n",
    "            model.save_weights(f\"weights/{model_name}.hdf5\")\n",
    "            # model.save(\"model_double_loss.keras\", overwrite=True)\n",
    "        # if epoch % 5 == 0:\n",
    "        #     [(get_example(f\"{no}.npy\", epoch) if full_dataset else get_example(no, epoch)) for no in (range(17119, 17124) if full_dataset else range(743, 748))]\n",
    "\n",
    "    # [(get_example(f\"{no}.npy\", epoch) if full_dataset else get_example(no, epoch)) for no in (range(17119, 17124) if full_dataset else range(743, 748))]\n",
    "    return losses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model number: 0 / 5\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=0.0>\n",
      "\n",
      "Epoch 1/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/43 [00:00<?, ?it/s]2025-07-10 08:54:03.701506: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8907\n",
      "2025-07-10 08:54:05.056385: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-10 08:54:05.056411: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-10 08:54:05.171158: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-10 08:54:05.171204: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      " 98%|█████████▊| 42/43 [00:47<00:00,  1.06it/s]2025-07-10 08:54:50.545059: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-10 08:54:50.545096: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-10 08:54:50.610908: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-07-10 08:54:50.610947: W tensorflow/core/common_runtime/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.09GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "100%|██████████| 43/43 [00:48<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.684582395609035\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.34499484>\n",
      "Epoch 1: Val loss = 0.48820085525512696, CCE loss = 0.4515601634979248, SAL loss = 0.5981229305267334\n",
      "\n",
      "Epoch 2/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:45<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.4663731344910555\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.68974274>\n",
      "Epoch 2: Val loss = 0.37547715902328493, CCE loss = 0.35070822238922117, SAL loss = 0.4497839629650116\n",
      "\n",
      "Epoch 3/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:45<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.3843692582707072\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.0344253>\n",
      "Epoch 3: Val loss = 0.34010018706321715, CCE loss = 0.32044883966445925, SAL loss = 0.39905421137809755\n",
      "\n",
      "Epoch 4/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:44<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.32773617880288947\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.3790109>\n",
      "Epoch 4: Val loss = 0.31340560913085935, CCE loss = 0.2960057437419891, SAL loss = 0.3656051754951477\n",
      "\n",
      "Epoch 5/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:44<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.28429588467575784\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.7234553>\n",
      "Epoch 5: Val loss = 0.28270627856254577, CCE loss = 0.2687075674533844, SAL loss = 0.32470242977142333\n",
      "\n",
      "Epoch 6/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:43<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.2501695561547612\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.0677252>\n",
      "Epoch 6: Val loss = 0.2586905717849731, CCE loss = 0.24975144267082214, SAL loss = 0.2855079710483551\n",
      "\n",
      "Epoch 7/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:43<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.22356439364510913\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.4117827>\n",
      "Epoch 7: Val loss = 0.2369253396987915, CCE loss = 0.23039000034332274, SAL loss = 0.256531348824501\n",
      "\n",
      "Epoch 8/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:41<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.2028178517208543\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.7554302>\n",
      "Epoch 8: Val loss = 0.22224188446998597, CCE loss = 0.2192826896905899, SAL loss = 0.23111947774887084\n",
      "\n",
      "Epoch 9/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [00:51<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.18786905498005624\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.9704535>\n",
      "Epoch 9: Val loss = 0.20980015397071838, CCE loss = 0.21061665713787078, SAL loss = 0.20735065639019012\n",
      "\n",
      "Epoch 10/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.17645587373611538\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.8675535>\n",
      "Epoch 10: Val loss = 0.2010723739862442, CCE loss = 0.20384102463722228, SAL loss = 0.1927664190530777\n",
      "\n",
      "Epoch 11/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:23<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss = 0.1651453212943188\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.5570755>\n",
      "Epoch 11: Val loss = 0.19255613386631013, CCE loss = 0.19786257445812225, SAL loss = 0.17663681805133818\n",
      "\n",
      "Epoch 12/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:23<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss = 0.15475494882395102\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.2134874>\n",
      "Epoch 12: Val loss = 0.18570585548877716, CCE loss = 0.1929406225681305, SAL loss = 0.16400156021118165\n",
      "\n",
      "Epoch 13/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss = 0.145605014160622\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.8696644>\n",
      "Epoch 13: Val loss = 0.1758376806974411, CCE loss = 0.18387775123119354, SAL loss = 0.15171746611595155\n",
      "\n",
      "Epoch 14/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:23<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss = 0.13568971652624218\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.5256641>\n",
      "Epoch 14: Val loss = 0.1697605222463608, CCE loss = 0.179488468170166, SAL loss = 0.14057668149471284\n",
      "\n",
      "Epoch 15/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss = 0.12649228839680207\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.1815429>\n",
      "Epoch 15: Val loss = 0.16201443672180177, CCE loss = 0.1718098431825638, SAL loss = 0.1326282098889351\n",
      "\n",
      "Epoch 16/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss = 0.11737399808196135\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.8373166>\n",
      "Epoch 16: Val loss = 0.1543286144733429, CCE loss = 0.16503534317016602, SAL loss = 0.12220843434333802\n",
      "\n",
      "Epoch 17/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss = 0.10749616751144099\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.49298435>\n",
      "Epoch 17: Val loss = 0.14828409850597382, CCE loss = 0.15946458876132966, SAL loss = 0.11474263817071914\n",
      "\n",
      "Epoch 18/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss = 0.09906641255284465\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.14858697>\n",
      "Epoch 18: Val loss = 0.1405856728553772, CCE loss = 0.15045047104358672, SAL loss = 0.11099126636981964\n",
      "\n",
      "Epoch 19/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss = 0.08989332650983056\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=0.19585454>\n",
      "Epoch 19: Val loss = 0.13343444615602493, CCE loss = 0.14325905740261077, SAL loss = 0.10396059900522232\n",
      "\n",
      "Epoch 20/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss = 0.08171538176924684\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=0.54033625>\n",
      "Epoch 20: Val loss = 0.12701386362314224, CCE loss = 0.13620179891586304, SAL loss = 0.09945006668567657\n",
      "\n",
      "Epoch 21/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Loss = 0.07307908372130505\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=0.88483405>\n",
      "Epoch 21: Val loss = 0.12024753987789154, CCE loss = 0.129504257440567, SAL loss = 0.09247739166021347\n",
      "\n",
      "Epoch 22/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Loss = 0.06584655328891999\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=1.2293195>\n",
      "Epoch 22: Val loss = 0.11779405176639557, CCE loss = 0.126967716217041, SAL loss = 0.0902730643749237\n",
      "\n",
      "Epoch 23/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Loss = 0.059185920326515686\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=1.5737602>\n",
      "Epoch 23: Val loss = 0.11186403930187225, CCE loss = 0.12060607373714446, SAL loss = 0.08563794195652008\n",
      "\n",
      "Epoch 24/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Loss = 0.052244799948015876\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=1.9181556>\n",
      "Epoch 24: Val loss = 0.11280086934566498, CCE loss = 0.12208385467529297, SAL loss = 0.08495191782712937\n",
      "\n",
      "Epoch 25/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Loss = 0.046405041547015656\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.262494>\n",
      "Epoch 25: Val loss = 0.10955334305763245, CCE loss = 0.11944386512041091, SAL loss = 0.07988177537918091\n",
      "\n",
      "Epoch 26/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Loss = 0.04173495568508326\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 26: Val loss = 0.1094952404499054, CCE loss = 0.11987784653902053, SAL loss = 0.07834742441773415\n",
      "\n",
      "Epoch 27/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Loss = 0.039128667393396065\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 27: Val loss = 0.1058355689048767, CCE loss = 0.116098353266716, SAL loss = 0.07504722774028778\n",
      "\n",
      "Epoch 28/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Loss = 0.03691022968742737\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 28: Val loss = 0.1100669413805008, CCE loss = 0.12181490361690521, SAL loss = 0.07482305392622948\n",
      "\n",
      "Epoch 29/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Loss = 0.035403631887463635\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 29: Val loss = 0.10221236944198608, CCE loss = 0.11277838796377182, SAL loss = 0.07051431164145469\n",
      "\n",
      "Epoch 30/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Loss = 0.0342686178032742\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 30: Val loss = 0.0990350604057312, CCE loss = 0.1077562391757965, SAL loss = 0.07287152335047722\n",
      "\n",
      "Epoch 31/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Loss = 0.03296401299709498\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 31: Val loss = 0.09844201952219009, CCE loss = 0.10737311542034149, SAL loss = 0.07164873406291009\n",
      "\n",
      "Epoch 32/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Loss = 0.03195516561526199\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 32: Val loss = 0.10424167215824127, CCE loss = 0.11559642255306243, SAL loss = 0.07017742246389388\n",
      "\n",
      "Epoch 33/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Loss = 0.031072286282514416\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 33: Val loss = 0.10370488613843917, CCE loss = 0.1135579451918602, SAL loss = 0.0741457112133503\n",
      "\n",
      "Epoch 34/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Loss = 0.03011018969118595\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 34: Val loss = 0.09722579866647721, CCE loss = 0.106343112885952, SAL loss = 0.06987385898828506\n",
      "\n",
      "Epoch 35/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Loss = 0.029608419035063234\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 35: Val loss = 0.10716478377580643, CCE loss = 0.11892312914133071, SAL loss = 0.07188975885510444\n",
      "\n",
      "Epoch 36/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Loss = 0.02857891920694085\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 36: Val loss = 0.10267282873392106, CCE loss = 0.11306425631046295, SAL loss = 0.07149854302406311\n",
      "\n",
      "Epoch 37/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Loss = 0.028146488635345947\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 37: Val loss = 0.1056624636054039, CCE loss = 0.11835528761148453, SAL loss = 0.0675839900970459\n",
      "\n",
      "Epoch 38/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Loss = 0.02730654188713362\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 38: Val loss = 0.1025979533791542, CCE loss = 0.11316372901201248, SAL loss = 0.07090062201023102\n",
      "\n",
      "Epoch 39/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Loss = 0.026859426611038142\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 39: Val loss = 0.10128864347934723, CCE loss = 0.11246154755353928, SAL loss = 0.06776992306113243\n",
      "\n",
      "Epoch 40/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Loss = 0.026432077941852948\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 40: Val loss = 0.101090969145298, CCE loss = 0.11286645084619522, SAL loss = 0.06576452478766441\n",
      "\n",
      "Epoch 41/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Loss = 0.025878821607939032\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 41: Val loss = 0.10017786622047424, CCE loss = 0.11140161156654357, SAL loss = 0.06650662198662757\n",
      "\n",
      "Epoch 42/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Loss = 0.025433522280912068\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 42: Val loss = 0.10467666983604432, CCE loss = 0.11677868217229843, SAL loss = 0.06837064325809479\n",
      "\n",
      "Epoch 43/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Loss = 0.024980428736916808\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 43: Val loss = 0.10277732163667679, CCE loss = 0.11471011489629745, SAL loss = 0.0669789470732212\n",
      "\n",
      "Epoch 44/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Loss = 0.024592455563157103\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 44: Val loss = 0.10210460722446442, CCE loss = 0.11323513090610504, SAL loss = 0.06871304139494896\n",
      "\n",
      "Epoch 45/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Loss = 0.02413242908064709\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 45: Val loss = 0.1061039537191391, CCE loss = 0.11878473162651063, SAL loss = 0.06806162074208259\n",
      "\n",
      "Epoch 46/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Loss = 0.023840613056753956\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 46: Val loss = 0.09990697354078293, CCE loss = 0.11159066706895829, SAL loss = 0.06485589072108269\n",
      "\n",
      "Epoch 47/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Loss = 0.023524600665929707\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 47: Val loss = 0.09452741891145706, CCE loss = 0.10410120636224747, SAL loss = 0.06580605581402779\n",
      "\n",
      "Epoch 48/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Loss = 0.022926318177650142\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 48: Val loss = 0.10119240581989289, CCE loss = 0.11233372241258621, SAL loss = 0.06776844635605812\n",
      "\n",
      "Epoch 49/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Loss = 0.02293262821297313\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 49: Val loss = 0.10485659837722779, CCE loss = 0.11725721657276153, SAL loss = 0.06765473410487174\n",
      "\n",
      "Epoch 50/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Loss = 0.0223335939957652\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 50: Val loss = 0.10113754570484161, CCE loss = 0.11301215291023255, SAL loss = 0.0655137225985527\n",
      "\n",
      "Epoch 51/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Loss = 0.022016600294168607\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 51: Val loss = 0.10445168763399124, CCE loss = 0.116414675116539, SAL loss = 0.06856272220611573\n",
      "\n",
      "Epoch 52/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Loss = 0.02179776337864094\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 52: Val loss = 0.10737966001033783, CCE loss = 0.12071189284324646, SAL loss = 0.06738296747207642\n",
      "\n",
      "Epoch 53/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Loss = 0.02143604932136314\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 53: Val loss = 0.10224479585886001, CCE loss = 0.11403994709253311, SAL loss = 0.06685934662818908\n",
      "\n",
      "Epoch 54/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Loss = 0.021299753186487875\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 54: Val loss = 0.10604550242424012, CCE loss = 0.11950252652168274, SAL loss = 0.06567444428801536\n",
      "\n",
      "Epoch 55/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Loss = 0.021302779031874136\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 55: Val loss = 0.09952979385852814, CCE loss = 0.11213545501232147, SAL loss = 0.061712803691625594\n",
      "\n",
      "Epoch 56/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Loss = 0.02083543993446023\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 56: Val loss = 0.10120021551847458, CCE loss = 0.11245483756065369, SAL loss = 0.06743634641170501\n",
      "\n",
      "Epoch 57/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Loss = 0.020360766801723214\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 57: Val loss = 0.10011443644762039, CCE loss = 0.11098105907440185, SAL loss = 0.06751457154750824\n",
      "\n",
      "Epoch 58/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Loss = 0.02021934343285339\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 58: Val loss = 0.10522065758705139, CCE loss = 0.11789603233337402, SAL loss = 0.06719453707337379\n",
      "\n",
      "Epoch 59/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Loss = 0.019943516419897247\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 59: Val loss = 0.1033021405339241, CCE loss = 0.11664522439241409, SAL loss = 0.06327287778258324\n",
      "\n",
      "Epoch 60/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Loss = 0.01974682124374911\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 60: Val loss = 0.10782011300325393, CCE loss = 0.12134888619184495, SAL loss = 0.06723380163311958\n",
      "\n",
      "Epoch 61/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Loss = 0.019646318780994692\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 61: Val loss = 0.09847012907266617, CCE loss = 0.11002053916454316, SAL loss = 0.06381890699267387\n",
      "\n",
      "Epoch 62/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Loss = 0.019655898646559825\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 62: Val loss = 0.10174012333154678, CCE loss = 0.11485610455274582, SAL loss = 0.06239217519760132\n",
      "\n",
      "Epoch 63/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Loss = 0.019222667765652023\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 63: Val loss = 0.10489739030599594, CCE loss = 0.11735107004642487, SAL loss = 0.06753635108470916\n",
      "\n",
      "Epoch 64/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Loss = 0.019105388111499852\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 64: Val loss = 0.09711200147867202, CCE loss = 0.10779420733451843, SAL loss = 0.06506538465619087\n",
      "\n",
      "Epoch 65/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Loss = 0.018721413257163623\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 65: Val loss = 0.09777692854404449, CCE loss = 0.10809014439582824, SAL loss = 0.06683729067444802\n",
      "\n",
      "Epoch 66/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:24<00:00,  1.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Loss = 0.018627788914844047\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 66: Val loss = 0.10236487090587616, CCE loss = 0.11472157090902328, SAL loss = 0.0652947723865509\n",
      "\n",
      "Epoch 67/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Loss = 0.018440618136421193\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 67: Val loss = 0.10164249241352082, CCE loss = 0.11475742012262344, SAL loss = 0.0622977003455162\n",
      "\n",
      "Epoch 68/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Loss = 0.018191161457189294\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 68: Val loss = 0.10395650118589402, CCE loss = 0.11616110205650329, SAL loss = 0.0673427015542984\n",
      "\n",
      "Epoch 69/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Loss = 0.01812722772186579\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 69: Val loss = 0.10323339700698853, CCE loss = 0.11612403988838196, SAL loss = 0.06456147357821465\n",
      "\n",
      "Epoch 70/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:25<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Loss = 0.018074245213769203\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 70: Val loss = 0.0993536040186882, CCE loss = 0.11104211807250977, SAL loss = 0.06428806632757186\n",
      "\n",
      "Epoch 71/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Loss = 0.0179211089907344\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 71: Val loss = 0.10171534717082978, CCE loss = 0.11588154584169388, SAL loss = 0.05921675190329552\n",
      "\n",
      "Epoch 72/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Loss = 0.017792599643905494\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 72: Val loss = 0.10555335879325867, CCE loss = 0.11954717338085175, SAL loss = 0.06357191950082779\n",
      "\n",
      "Epoch 73/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Loss = 0.0176644389149408\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 73: Val loss = 0.11015292555093766, CCE loss = 0.12415017783641816, SAL loss = 0.06816117018461228\n",
      "\n",
      "Epoch 74/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Loss = 0.017427620564609073\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 74: Val loss = 0.10827066600322724, CCE loss = 0.1221707358956337, SAL loss = 0.06657044887542725\n",
      "\n",
      "Epoch 75/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Loss = 0.01715973717008912\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=2.5>\n",
      "Epoch 75: Val loss = 0.1150933250784874, CCE loss = 0.13057811111211776, SAL loss = 0.06863896399736405\n",
      "Model number: 1 / 5\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=0.0>\n",
      "\n",
      "Epoch 1/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:21<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.6819790255191714\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.3450074>\n",
      "Epoch 1: Val loss = 0.49190741777420044, CCE loss = 0.456483793258667, SAL loss = 0.5981782913208008\n",
      "\n",
      "Epoch 2/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.4737088936705922\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-0.6897788>\n",
      "Epoch 2: Val loss = 0.3861479163169861, CCE loss = 0.3610632836818695, SAL loss = 0.46140179634094236\n",
      "\n",
      "Epoch 3/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.38600004551022554\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.0344703>\n",
      "Epoch 3: Val loss = 0.3463316857814789, CCE loss = 0.32625911235809324, SAL loss = 0.4065494179725647\n",
      "\n",
      "Epoch 4/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.32875541545623954\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.3790544>\n",
      "Epoch 4: Val loss = 0.3181156098842621, CCE loss = 0.29952366948127745, SAL loss = 0.37389141917228697\n",
      "\n",
      "Epoch 5/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.28629263958265616\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-1.7235086>\n",
      "Epoch 5: Val loss = 0.29495216608047486, CCE loss = 0.2786415576934814, SAL loss = 0.34388397336006166\n",
      "\n",
      "Epoch 6/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.25242895338424415\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.0678003>\n",
      "Epoch 6: Val loss = 0.2720090389251709, CCE loss = 0.25792683362960817, SAL loss = 0.31425564289093016\n",
      "\n",
      "Epoch 7/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.22861512906329576\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.4119122>\n",
      "Epoch 7: Val loss = 0.2530597150325775, CCE loss = 0.24172333180904387, SAL loss = 0.2870688736438751\n",
      "\n",
      "Epoch 8/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:20<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.2086933012618575\n",
      "Softmax weight = <tf.Variable 'softmax_pooling/beta:0' shape=() dtype=float32, numpy=-2.7556987>\n",
      "Epoch 8: Val loss = 0.23352643549442292, CCE loss = 0.2264213055372238, SAL loss = 0.2548418253660202\n",
      "\n",
      "Epoch 9/75 \n",
      "Alpha = 0.75, Beta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 9/43 [00:17<01:04,  1.90s/it]"
     ]
    }
   ],
   "source": [
    "losses_all = []\n",
    "cce_loss_all = []\n",
    "sal_loss_all = []\n",
    "predictions_hist_test_all = []\n",
    "alpha_og, beta_og = alpha_loss, beta_loss\n",
    "for mo_no in range(no_models):\n",
    "    print(f\"Model number: {mo_no} / {no_models}\")\n",
    "    alpha_loss, beta_loss = alpha_og, beta_og\n",
    "\n",
    "    combined_loss_li = []\n",
    "    cce_loss_li = []\n",
    "    sal_loss_li = []\n",
    "    predictions_hist_train = []\n",
    "    predictions_hist_test = []\n",
    "    if 'base_model' in locals():\n",
    "        del base_model\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    if 'optimizer' in locals():\n",
    "        del optimizer\n",
    "    # if 'beta_optimizer' in locals():\n",
    "    #     del beta_optimizer\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50V2(include_top=False, weights=\"imagenet\")\n",
    "    model = create_model_with_spatial_scores(base_model, no_classes + 1, use_max, pool_layer, start_value=beta_start_val, beta_cap_value=max_beta_val)\n",
    "    losses_hist = []\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    # beta_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate * beta_lr_factor)\n",
    "\n",
    "    losses_hist = train_model(model, dataset, epochs,\n",
    "                optimizer,\n",
    "                alpha_loss, beta_loss, losses=losses_hist, train_split=train_size)\n",
    "\n",
    "    losses_all.append(losses_hist)\n",
    "    sal_loss_all.append(sal_loss_li)\n",
    "    cce_loss_all.append(cce_loss_li)\n",
    "    predictions_hist_test_all.append(predictions_hist_test)\n",
    "\n",
    "    if 'base_model' in locals():\n",
    "        del base_model\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    if 'optimizer' in locals():\n",
    "        del optimizer\n",
    "    # if 'beta_optimizer' in locals():\n",
    "    #     del beta_optimizer\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.shape(predictions_hist_test_all[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(f\"losses/multipleModels/{model_name}_cce_loss.npy\", cce_loss_all)\n",
    "np.save(f\"losses/multipleModels/{model_name}_sal_loss.npy\", sal_loss_all)\n",
    "np.save(f\"losses/multipleModels/{model_name}_predictions.npy\", predictions_hist_test_all)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
